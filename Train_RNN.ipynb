{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Text RNN Tensorflow - TUTORIAL\n",
    "\n",
    "This notebook describes how to train a RNN model, in order to generate the next word of a sentence (word by word).\n",
    "The training is done using a full text (whatever you want: novel, etc.).\n",
    "\n",
    "Before going through this tutorial, I suggest to read the very very good blog note from Andrej Karpathy: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "This project takes also a lot from : https://github.com/hunkim/word-rnn-tensorflow by hunkim.\n",
    "(honestly: almost every thing, this word-rnn-tensorflow project is so great)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "\n",
    "from simple_model import Model\n",
    "\n",
    "import codecs\n",
    "import collections\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variables\n",
    "\n",
    "We create variables required to train our neural net, to save the model, retrieve data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/Artistes_et_Phalanges-David_Campion'# data directory containing input.txt\n",
    "input_encoding = None # character encoding of input.txt, from https://docs.python.org/3/library/codecs.html#standard-encodings'\n",
    "log_dir = 'logs'# directory containing tensorboard logs\n",
    "save_dir = 'save' # directory to store checkpointed models\n",
    "rnn_size = 256 # size of RNN hidden state\n",
    "num_layers = 2 # number of layers in the RNN\n",
    "model = 'lstm' # lstm model\n",
    "batch_size = 50 # minibatch size\n",
    "seq_length = 25 # RNN sequence length\n",
    "num_epochs = 25 # number of epochs\n",
    "save_every = 1000 # save frequency\n",
    "grad_clip = 5. #clip gradients at this value\n",
    "learning_rate= 0.002 #learning rate\n",
    "decay_rate = 0.97 #decay rate for rmsprop\n",
    "gpu_mem = 0.666 #%% of gpu memory to be allocated to this process. Default is 66.6%%\n",
    "init_from = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data\n",
    "\n",
    "First step is to ingest data from the text (input.txt file) and prepare inputs and targets for the training.\n",
    "\n",
    "### Load Data\n",
    "The objective of this section is to process the full text.\n",
    "\n",
    "It's very easy to modify this part to change the way data are used.\n",
    "Here, the code split every words from the text, however we could do similar operation to split every characters, etc.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = os.path.join(data_dir, \"input.txt\")\n",
    "vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "tensor_file = os.path.join(data_dir, \"data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening of the input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(input_file, \"r\", encoding=None) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split all sentences, word by word.\n",
    "\n",
    "**Note**: this command will split words based on spaces.\n",
    "If a dot or a comma is closed/attached to a word, it will be added to it.\n",
    "\n",
    "You can modify this cell in order to refine the way words are extracted (even splitting by characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_text = data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary\n",
    "The next step is to build a vocabulary mapping from word to index based on the previous sentences.\n",
    "\n",
    "In order to to that, we have to define:\n",
    "\n",
    "- vocabulary mapping (word -> index)\n",
    "- inverse vocabulary mapping. (index -> word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of words\n",
    "word_counts = collections.Counter(x_text)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the size of the vocabulary is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the vocabulary file. Could ber usefull later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(vocab_file, 'wb') as f:\n",
    "    cPickle.dump((words), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor creation\n",
    "We create the tensor based on the vocalubary, then we save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensor = np.array(list(map(vocab.get, x_text)))\n",
    "\n",
    "# Save the data to data.npy\n",
    "np.save(tensor_file, tensor)\n",
    "\n",
    "print('tensor is:' + str(tensor))\n",
    "print(\"It's shape: \" + str(np.shape(tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create batches\n",
    "First, we calculate the number of batches we can use to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_batches = int(tensor.size / (batch_size * seq_length))\n",
    "print('number of batches is: ' + str(num_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we modify the tensor, following the real number of batches.\n",
    "\n",
    "We select only the firsts values required for all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensor = tensor[:num_batches * batch_size * seq_length]\n",
    "print('The shape of the new tensor is: '+ str(np.shape(tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to define **'inputs'** (xdata) and **'targets'** (ydata) data for the training.\n",
    "\n",
    "In our tutorial, due to our objectives, they are similar in term of shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata = tensor\n",
    "ydata = np.copy(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to set-up correctely the targets (ydata).\n",
    "\n",
    "in our exemple, we want to __predict the next words of a sentence__, so __ydata__ is a shift by one word from __xdata__.\n",
    "In order to have a __ydata__ with the same shape, we copy the first component of __xdata__ to the last one of __ydata__.\n",
    "\n",
    "Dumb example: if the complete xdata is: \"the quick brown fox jumps over the lazy dog\"\n",
    "- xdata = [the, quick, brown, fox, jumps, over, the, lazy, dog]\n",
    "- ydata = [quick, brown, fox, jumps, over, the, lazy, dog, the]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create batches: we split xdata and ydata in several batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\n",
    "y_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset batch pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save words and vocabs.\n",
    "\n",
    "It will be usefull when we would like to generate text from a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'wb') as f:\n",
    "    cPickle.dump((words, vocab), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Model\n",
    "\n",
    "We create the model.\n",
    "If you want to deep dive inside, please have a look to the Model class in the __*simple_model.py*__ file.\n",
    "\n",
    "__*simple_model.py*__ file describes a model class, with function to train it and to generate text.\n",
    "\n",
    "Note: By default, the RNN is a LTSM network. You can easily switch to another type by modifying the python script (simple RNN or GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(data_dir,input_encoding,log_dir,save_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we create a \"writer\" to populate logs file.\n",
    "It will be very usefull display additional infomation from __tensorboard__.\n",
    "\n",
    "In order to do that:\n",
    "- we merge all summaries collected in the default graph,\n",
    "- then we create a summary writer, that will save info in the log folder.\n",
    "\n",
    "__Note:__\n",
    "From a separate console line, run the following:\n",
    "\n",
    "      tensorboard --logdir=./logs/\n",
    "\n",
    "This command will start Tensorboard. Then, info will be available on the following url:\n",
    "    http://0.0.0.0:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last, we set up a variable for gpu options of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "Here is the big part.\n",
    "\n",
    "The following section describes how to open a session :\n",
    "- add the graph to the writer (for the log)\n",
    "- global variable initialization,\n",
    "- creation of a saver to store models in files,\n",
    "- for each epochs:\n",
    "     - assign the learning rate for the epoch,\n",
    "     - reinitilization of variables:\n",
    "         - pointer for batches,\n",
    "         - state of the model,\n",
    "         - variable to calculate speed.\n",
    "     - then loop over all batches:\n",
    "         - select x and y for the active batch,\n",
    "         - set the feeding string for the model,\n",
    "         - train the model,\n",
    "         - display some info in the console,\n",
    "         - save the model sometimes\n",
    "- close de session.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        #add the session graph to the writer\n",
    "        train_writer.add_graph(sess.graph)\n",
    "\n",
    "        #initialize global variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        #create the Saver to save the model and its variables.\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "        #create a for loop, to run over all epochs (defined as e)\n",
    "        for e in range(model.epoch_pointer.eval(), num_epochs):\n",
    "            #a session encapsulates the environement in which operations objects are executed.\n",
    "                        \n",
    "            #Initialization:\n",
    "            \n",
    "            #here we assign to the lr (learning rate) value of the model, the value : args.learning_rate * (args.decay_rate ** e))\n",
    "            sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "            \n",
    "            #we define the state of the model. At the beginning, its the initial state of the model.\n",
    "            state = sess.run(model.initial_state)\n",
    "            #speed to 0 at the beginning.\n",
    "            speed = 0\n",
    "            #reinitialize pointer for batches\n",
    "            pointer = 0\n",
    "            \n",
    "            if init_from is None:\n",
    "                assign_op = model.epoch_pointer.assign(e)\n",
    "                sess.run(assign_op)\n",
    "\n",
    "            if init_from is not None:\n",
    "                pointer = model.batch_pointer.eval()\n",
    "                init_from = None\n",
    "\n",
    "            #in each epoch, for loop to run over each batch (b)\n",
    "            for b in range(pointer, num_batches):\n",
    "                #define the starting date:\n",
    "                start = time.time()\n",
    "                #define x and y for the next batch\n",
    "                x, y = x_batches[pointer], y_batches[pointer]\n",
    "                pointer += 1\n",
    "\n",
    "                #create the feeding string for the model.\n",
    "                #input data are x, targets are y, the initiate state is state, and batch time 0.\n",
    "                feed = {model.input_data: x, model.targets: y, model.initial_state: state,\n",
    "                        model.batch_time: speed}\n",
    "\n",
    "                #run the session and train.\n",
    "                summary, train_loss, state, _, _ = sess.run([merged, model.cost, model.final_state,\n",
    "                                                             model.train_op, model.inc_batch_pointer_op], feed)\n",
    "                #add summary to the log\n",
    "                train_writer.add_summary(summary, e * num_batches + b)\n",
    "\n",
    "                #calculate the speed of the batch.\n",
    "                #this information will be displayed later.\n",
    "                speed = time.time() - start\n",
    "\n",
    "                #display something in the console\n",
    "                #---------------------------------\n",
    "                #print information:\n",
    "                if (e * num_batches + b) % batch_size == 0:\n",
    "                    print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                        .format(e * num_batches + b,\n",
    "                                num_epochs * num_batches,\n",
    "                                e, train_loss, speed))\n",
    "                \n",
    "                #save model:\n",
    "                if (e * num_batches + b) % save_every == 0 \\\n",
    "                        or (e==num_epochs-1 and b == num_batches-1): # save for the last result\n",
    "                    #define the path to the model\n",
    "                    checkpoint_path = os.path.join(save_dir, 'model_test.ckpt')\n",
    "                    #save the model, woth increment ()\n",
    "                    saver.save(sess, checkpoint_path, global_step = e * num_batches + b)\n",
    "                    print(\"model saved to {}\".format(checkpoint_path))\n",
    "        \n",
    "        #close the session\n",
    "        train_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now...\n",
    "Now, the model is trained and stored locally. It can be used to generate sample of text !\n",
    "\n",
    "Open the notebook __**Generate_text**__ to continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
